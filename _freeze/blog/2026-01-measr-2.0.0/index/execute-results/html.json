{
  "hash": "eaf49bdaedf9277a2b6e8c83a7d7ec08",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"measr 2.0.0\"\ndate: 2026-01-13\nsubtitle: \"\"\ndescription: \"Major release to introduce new model specifications and evaluation methods.\"\nimage: \"featured.jpg\"\nimage-alt: \"Sections of rulers and measuring tape.\"\ntitle-block-banner: featured.jpg\ntwitter-card:\n  image: \"featured.jpg\"\nopen-graph:\n  image: \"featured.jpg\"\nengine: knitr\n# doi: 10.59350/1kz71-zdj91\ncitation: true\n# one of: \"deep-dive\", \"learn\", \"package\", or \"other\" + relevant packages\ncategories:\n  - package\n  - measr\n---\n\n\n\nWe are ecstatic to announce the release of `{measr}` 2.0.0.\nmeasr is an [*R*](https://r-project.org) package for estimating and evaluating diagnostic classification models (DCMs). \nYou can specify a variety of DCMs, choose a [*Stan*](https://mc-stan.org) backend and estimation method, and then evaluate the model using a wide range of model fit analyses.\n\nYou can install measr from CRAN with:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"measr\")\n```\n:::\n\n\nThis blog post highlights the most important changes in this release, including a decoupling of measr's functionality, a new interface for specifying and estimating models, and many new functions for model evaluation.\nYou can see a full list of changes in the [release notes](https://measr.r-dcm.org/news/index.html#measr-200).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(measr)\n```\n:::\n\n\n## Introducing r-dcm\n\nA major focus of development work since the previous release has been to modularize the functionality of measr, creating smaller and more focused packages that are easier to maintain and quickly update with new features.\nFunctionality for model estimation and evaluation remains the purview of measr.\nHowever, previously, DCMs were specified within the same function call as model estimation using `measr_dcm()`.\nThis created confusion and blurred the lines between how the model was defined and how it was estimated.\n\nTherefore, the specification of DCMs, including the creation of Stan scripts, is now handled by the new `{dcmstan}` package.\nThis decoupling allows for more flexible model specifications and will also allow us to more quickly add new model types without disrupting model estimation functionality in measr.\n\nAdditionally, the example data sets have been split out into their own package, `{dcmdata}`, allowing the data sets to be easily used across both measr and dcmstan (and future packages) without creating troublesome recursive dependencies between packages.\n\n:::{.columns .v-center}\n\n:::{.column width=\"30%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](https://raw.githubusercontent.com/r-dcm/hex-stickers/refs/heads/main/svg/dcmstan.svg){fig-align='center' fig-alt='dcmstan hex logo.' width=85%}\n:::\n:::\n\n\n:::\n\n:::{.column width=\"5%\"}\n<!-- empty column to create gap -->\n:::\n\n:::{.column width=\"30%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](https://raw.githubusercontent.com/r-dcm/hex-stickers/refs/heads/main/svg/measr.svg){fig-align='center' fig-alt='measr hex logo' width=100%}\n:::\n:::\n\n\n:::\n\n:::{.column width=\"5%\"}\n<!-- empty column to create gap -->\n:::\n\n:::{.column width=\"30%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](https://raw.githubusercontent.com/r-dcm/hex-stickers/refs/heads/main/svg/dcmdata.svg){fig-align='center' fig-alt='dcmdata hex logo' width=85%}\n:::\n:::\n\n\n:::\n\n:::\n\nIn most cases, you will only need to load measr as relevant functions (e.g., `dcm_specify()` from dcmstan) are reexported by measr.\nSo while there are some significant changes on the backend, the transition should be (hopefully) seamless for users.\n\n## Specification and estimation\n\nAs part of the decoupling of functionality, we have also decoupled model specification and estimation.\nConceptually, the model specification is separate from model estimation.\nThat is, the choice of model (e.g., DINA vs. LCDM) should not impact model estimation choices (e.g., MCMC vs. optimization, estimation engine).\nTherefore, decoupling also allows for a more intuitive user interface.\nUsing previous versions of measr, you would both specify and estimate a DCM with `measr_dcm()`.\nIn the following code, we estimate an LCDM with an unconstrained structural model, but we limit the LCDM to only contain intercepts, main effects, and two-way interactions (`max_interaction = 2`).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dcmdata)\n\n# old code\nmy_model <- measr_dcm(\n  data = ecpe_data,\n  qmatrix = ecpe_qmatrix,\n  resp_id = \"resp_id\",\n  item_id = \"item_id\",\n  type = \"lcdm\",\n  attribute_structure = \"unconstrained\",\n  max_interaction = 2,\n  method = \"mcmc\",\n  backend = \"cmdstanr\"\n)\n```\n:::\n\n\nHowever, this code is ambiguous.\nDoes the `max_interaction` apply to the `type`, the `attribute_structure`, or some other element of the model estimation process?\nThis information is clarified in the function documentation, but the code itself is not intuitive.\nUnder the new specification interface, additional arguments to measurement or structural models are now defined explicitly in the model specification.\nWe specify a model with `dcm_specify()`, and arguments that apply to a measurement or structural model are defined within that model's constructor.\nFor a list of all supported measurement and structural models and their associated arguments, see `?dcm_specify`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlcdm_spec <- dcm_specify(\n  qmatrix = ecpe_qmatrix,\n  identifier = \"item_id\",\n  measurement_model = lcdm(max_interaction = 2),\n  structural_model = unconstrained()\n)\n```\n:::\n\n\nWe can then use our model specification and `dcm_estimate()` to estimate the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlcdm <- dcm_estimate(\n  dcm_spec = lcdm_spec,\n  data = ecpe_data,\n  identifier = \"resp_id\",\n  method = \"variational\",\n  backend = \"rstan\",\n  file = \"fits/ecpe-lcdm\"\n)\n```\n:::\n\n\n`measr_dcm()` has been deprecated, but will continue to work with limited functionality, as new development work will go toward `dcm_specify()` and `dcm_estimate()`.\nUsing `measr_dcm()` will result in a warning that you should update your workflow.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlcdm <- measr_dcm(\n  data = ecpe_data,\n  qmatrix = ecpe_qmatrix,\n  resp_id = \"resp_id\",\n  item_id = \"item_id\",\n  type = \"lcdm\",\n  attribute_structure = \"unconstrained\",\n  method = \"variational\",\n  backend = \"cmdstanr\",\n  file = \"fits/ecpe-lcdm\"\n)\n#> Warning: `measr_dcm()` was deprecated in measr 2.0.0.\n#> ℹ This is a limited version of dcm_estimate(); use it instead.\n```\n:::\n\n\n### New model specifications\n\nSpeaking of new development work, we have added support for several new measurement and structural models.\nOn the measurement model side, we now support the noisy-input, deterministic \"and\" gate [`nida()`\\; @nida]; the noisy-input, deterministic \"or\" gate [`nido()`\\; @nido]; and the noncompensatory reparameterized unified model [`ncrum()`\\; @ncrum].\nThis means that we now support the specification and estimation of all 6 core DCMs identified by @rupp-dcm in addition to the general LCDM.\n\nWe also added support for the loglinear structural model [`loglinear()`\\; @loglinear], which allows the user to limit the interactions included between the attributes.\nWe also added support for attribute hierarchies.\nFor example, we might theorize that some attributes are dependent on others that represent prerequisite skills, as in the ECPE data set we used earlier.\nThis data set measures 3 attributes: morphosyntactic, cohesive, and lexical rules.\nThese attributes represent rules of the English language with increasing levels of complexity from lexical, to cohesive, and finally morphosyntactic.\nmeasr now supports two different ways to specify attribute relationships in a DCM.\nThe first is the hierarchical DCM [`hdcm()`\\; @hdcm], which enforces a strict hierarchy.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhdcm_spec <- dcm_specify(\n  qmatrix = ecpe_qmatrix,\n  identifier = \"item_id\",\n  measurement_model = lcdm(),\n  structural_model = hdcm(hierarchy = \"lexical -> cohesive -> morphosyntactic\")\n)\n```\n:::\n\n\nWe specify the `hierarchy` in our structural model using arrows to indicate the dependencies (see `vignette(\"attribute-hierarchies\", package = \"dcmstan\")` for more examples).\nAs we can see, the full model with an unconstrained structural model includes 8 possible attribute patterns.\nHowever, when we use the HDCM, only patterns that are consistent with the specified hierarchy are included in the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncreate_profiles(lcdm_spec)\n#> # A tibble: 8 × 3\n#>   morphosyntactic cohesive lexical\n#>             <int>    <int>   <int>\n#> 1               0        0       0\n#> 2               1        0       0\n#> 3               0        1       0\n#> 4               0        0       1\n#> 5               1        1       0\n#> 6               1        0       1\n#> 7               0        1       1\n#> 8               1        1       1\n\ncreate_profiles(hdcm_spec)\n#> # A tibble: 4 × 3\n#>   morphosyntactic cohesive lexical\n#>             <int>    <int>   <int>\n#> 1               0        0       0\n#> 2               0        0       1\n#> 3               0        1       1\n#> 4               1        1       1\n```\n:::\n\n\nThe second structural model that can support a user-defined hierarchy is a Bayesian network [`bayesnet()`\\; @bayesnet].\nWhen using a BayesNet, the hierarchical relationship is specified in the same way using `->` or `<-` to indicate dependencies.\nHowever, the BayesNet specification does not completely eliminate patterns that are inconsistent with the specified hierarchy.\nRather, inconsistent patterns are downweighted using conditional probabilities.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbn_spec <- dcm_specify(\n  qmatrix = ecpe_qmatrix,\n  identifier = \"item_id\",\n  measurement_model = lcdm(),\n  structural_model = bayesnet(\n    hierarchy = \"lexical -> cohesive -> morphosyntactic\"\n  )\n)\n```\n:::\n\n\nAll measurement and structural models can be mixed and matched in `dcm_specify()` to create a model that meets your needs and matches your conceptual understanding of the items and attributes.\n\n### Estimation improvements\n\nWe've also made some improvements to how models are estimated in the form of two new estimation methods for `dcm_estimate()`.\nFirst, we have added support for *Stan's* variational algorithm for approximate posterior sampling (`method = \"variational\"`).\nThis method will wrap `rstan::vb()` when using the rstan backend and `cmdstanr::variational()` when using cmdstanr.\n\nWe've also added support for *Stan's* pathfinder variational inference algorithm (`method = \"pathfinder\"`).\nThis method is similar to the variational method; however, the pathfinder algorithm is generally faster and more stable than the automatic differentiation algorithm that is used by `rstan::vb()` and `cmdstanr::variational()`.\nNotably, the pathfinder algorithm is not available in rstan, and therefore this method can only be used when using cmdstanr (wrapping `cmdstanr::pathfinder()`).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhdcm <- dcm_estimate(\n  dcm_spec = hdcm_spec,\n  data = ecpe_data,\n  identifier = \"resp_id\",\n  method = \"pathfinder\",\n  backend = \"cmdstanr\",\n  file = \"fits/ecpe-hdcm\"\n)\n```\n:::\n\n\nAlthough we still recommend using full posterior sampling when possible (`method = \"mcmc\"`), we recognize that this can be very slow for these models, and the variational algorithms should be much quicker.\n\n## Model evaluation updates\n\nWe added several new tools for evaluating a model once it is estimated.\nThese include updates to how to extract parameter estimates and other information from a model, new functions for evaluating model assumptions, and additional methods for conducting model comparisons.\n\n### Extract information\n\nWe've added a few new elements that can be extracted from a model with `measr_extract()`.\nWe can extract the base rate of proficiency or presence on each of the attributes with `what = \"attribute_base_rate\"`.\nWe can also now extract the &pi; matrix with `what = \"pi_matrix\"`, which is the estimated probability that a respondent in each class will provide a correct response to each item.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmeasr_extract(lcdm, what = \"attribute_base_rate\")\n#> # A tibble: 1 × 3\n#>   morphosyntactic     cohesive       lexical\n#>        <rvar[1d]>   <rvar[1d]>    <rvar[1d]>\n#> 1    0.38 ± 0.016  0.55 ± 0.02  0.67 ± 0.019\n\nmeasr_extract(lcdm, what = \"pi_matrix\")\n#> # A tibble: 28 × 9\n#>    item_id     `[0,0,0]`     `[1,0,0]`      `[0,1,0]`      `[0,0,1]`\n#>    <chr>      <rvar[1d]>    <rvar[1d]>     <rvar[1d]>     <rvar[1d]>\n#>  1 E1       0.69 ± 0.014  0.76 ± 0.030  0.81 ± 0.0227  0.69 ± 0.0138\n#>  2 E2       0.75 ± 0.011  0.75 ± 0.011  0.92 ± 0.0104  0.75 ± 0.0113\n#>  3 E3       0.42 ± 0.010  0.54 ± 0.023  0.42 ± 0.0104  0.52 ± 0.0300\n#>  4 E4       0.47 ± 0.013  0.47 ± 0.013  0.47 ± 0.0129  0.82 ± 0.0125\n#>  5 E5       0.76 ± 0.012  0.76 ± 0.012  0.76 ± 0.0123  0.96 ± 0.0065\n#>  6 E6       0.72 ± 0.014  0.72 ± 0.014  0.72 ± 0.0143  0.94 ± 0.0099\n#>  7 E7       0.47 ± 0.015  0.72 ± 0.059  0.47 ± 0.0150  0.68 ± 0.0206\n#>  8 E8       0.82 ± 0.011  0.82 ± 0.011  0.97 ± 0.0068  0.82 ± 0.0107\n#>  9 E9       0.54 ± 0.010  0.54 ± 0.010  0.54 ± 0.0105  0.80 ± 0.0121\n#> 10 E10      0.50 ± 0.012  0.88 ± 0.014  0.50 ± 0.0117  0.50 ± 0.0117\n#> # ℹ 18 more rows\n#> # ℹ 4 more variables: `[1,1,0]` <rvar[1d]>, `[1,0,1]` <rvar[1d]>,\n#> #   `[0,1,1]` <rvar[1d]>, `[1,1,1]` <rvar[1d]>\n```\n:::\n\n\nWe've also simplified the extract process.\nPreviously, many `what` options required that an analysis be added to a model before it could be extracted.\nFor example, if we tried to extract model fit information from a model, we would get an error telling us that model fit information need to first be added to the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# old code\nmeasr_extract(lcdm, what = \"m2\")\n#> Error: Model fit information must be added to a model object before the M2\n#> can be extracted. See add_fit().\"\n```\n:::\n\n\nNow, adding elements is no longer required.\nIf you request to extract something that has not been added, it will now automatically be calculated for the extract.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmeasr_extract(lcdm, what = \"m2\")\n#> # A tibble: 1 × 3\n#>      m2    df     pval\n#>   <dbl> <int>    <dbl>\n#> 1  531.   325 3.90e-12\n```\n:::\n\n\nNote that you can, and in many cases should, still add elements to a model with `add_fit()`, `add_criterion()`, `add_reliability()`, and `add_respondent_estimates()`.\nMany of these calculations are time consuming.\nIf you plan to extract a particular `what` many times, adding an element first means that the calculation will only happen once, whereas the calculation will need to be conducted every time `measr_extract()` is called if the element has not been added.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlcdm <- add_fit(lcdm, method = \"m2\")\nmeasr_extract(lcdm, \"m2\")\n#> # A tibble: 1 × 3\n#>      m2    df     pval\n#>   <dbl> <int>    <dbl>\n#> 1  531.   325 3.90e-12\n```\n:::\n\n\n### Check assumptions\n\nAs with any psychometric model, DCMs make assumptions that we should check.\nThis release comes with checks for two key assumptions: local item dependence and the accuracy of the Q-matrix.\n\nLocal item dependence refers to the assumption that item responses are independent of each other, conditional on the respondents' attribute patterns.\nThat is, after we account for the respondents attribute pattern, we should not see any additional or residual relationship among the items.\nThis is often checked using the Q~3~ statistic [@yenq3], which can now be calculated with `yens_q3()`.\n`yens_q3()` will calculate the residual correlations between items and optionally flag any item pairs above a critical value.\nA significant number of residual correlations, particularly if the same group of items are involved, may indicate additional dimensions (i.e., attributes) that should be included.\n\nWe can also evaluate the alignment of items to the attributes identified in the Q-matrix.\n`qmatrix_validation()` implements the method described by @delatorre2016 to determine if there are other Q-matrix specifications that would better explain the response data.\nFor example, in our ECPE model, item E9 measures only the third attribute (lexical rules) in the Q-matrix used to estimate the model.\nHowever, the data suggests that this item may also be measuring the first attribute (morphosyntactic rules).\nNote that this method will not evaluate whether the number of attributes is correct, only the item to attribute alignment.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqmatrix_validation(lcdm)\n#> # A tibble: 28 × 5\n#>    item_id original_specification original_pvaf empirical_specification\n#>    <chr>   <chr>                          <dbl> <chr>                  \n#>  1 E1      [1, 1, 0]                      0.994 <NA>                   \n#>  2 E2      [0, 1, 0]                      0.993 <NA>                   \n#>  3 E3      [1, 0, 1]                      0.996 <NA>                   \n#>  4 E4      [0, 0, 1]                      0.982 <NA>                   \n#>  5 E5      [0, 0, 1]                      0.993 <NA>                   \n#>  6 E6      [0, 0, 1]                      0.983 <NA>                   \n#>  7 E7      [1, 0, 1]                      0.999 <NA>                   \n#>  8 E8      [0, 1, 0]                      0.994 <NA>                   \n#>  9 E9      [0, 0, 1]                      0.909 [1, 0, 1]              \n#> 10 E10     [1, 0, 0]                      0.978 <NA>                   \n#> # ℹ 18 more rows\n#> # ℹ 1 more variable: empirical_pvaf <chr>\n```\n:::\n\n\n### Make comparisons\n\nFinally, we've also added support for Bayes factors for model comparisons.\n`bayes_factor()` will calculate the posterior probability that a model is correct, given our prior probability (specified through the `prior_prob` argument) and the calculated Bayes factor.\nNote the Bayes factors currently depend on the `{bridgesampling}` package, which does not support cmdstanr.\nTherefore, model comparisons with Bayes factors are only available when the models are estimated with full MCMC (`method = \"mcmc\"`) using rstan (`backend = \"rstan\"`).\nSupport for additional estimation methods and backends will be added as they are made available in bridgesampling.\n\n## Other new features\n\n* Users can now specify a probability classification threshold when calculating reliability metrics with `reliability()`.\n\n* Discrimination methods are now available through `cdi()` to evaluate how well an item or attribute can discern different classes.\n\n* `predict()` has been replaced by `score()` to be more intuitive. The model is estimated by predicting item responses; however, `predict()` returned respondent-level class and attribute probabilities. Thus, this function was renamed to better reflect its intended use.\n\n## Acknowledgments {.appendix}\n\n\n\nA big thank you to all the folks who helped make this release happen: [&#x0040;auburnjimenez34](https://github.com/auburnjimenez34), [&#x0040;dgkf](https://github.com/dgkf), [&#x0040;JeffreyCHoover](https://github.com/JeffreyCHoover), [&#x0040;ralmond](https://github.com/ralmond), and [&#x0040;wjakethompson](https://github.com/wjakethompson).\n\nThe research reported here was supported by the Institute of Education Sciences, U.S. Department of Education, through Grants [R305D210045](https://ies.ed.gov/use-work/awards/improving-software-and-methods-estimating-diagnostic-classification-models-and-evaluating-model-fit?ID=4546) and [R305D240032](https://ies.ed.gov/use-work/awards/expanding-functionality-and-accessibility-software-diagnostic-measurement?ID=6075) to the University of Kansas Center for Research, Inc., ATLAS. The opinions expressed are those of the authors and do not represent the views of the Institute or the U.S. Department of Education.\n\nFeatured photo by <a href=\"https://unsplash.com/@wwarby?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">William Warby</a> on <a href=\"https://unsplash.com/photos/gray-and-yellow-measures-WahfNoqbYnM?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">Unsplash</a>.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}